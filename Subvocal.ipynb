{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Classes\n",
    "\n",
    "First we get all of our helper modules. The prepare_EMG module will prepare the EMG data for phoneme recognition. The prepare_outputs module will prepare our target labels and align them with our EMG data. The module 'prepare_data' will help us read data from CSV into a dataframe. Finally, 'vis' will help visualize EMG data in both time and frequency domains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import prepare_EMG, prepare_outputs, prepare_data, vis\n",
    "# autodetector = Output_Prep.detector\n",
    "EMG_Prep = prepare_EMG.EMG_preparer()\n",
    "# Output_Prep = prepare_outputs.output_preparer(subvocal_detector = autodetector, window_size=30.0)\n",
    "Output_Prep = prepare_outputs.output_preparer()\n",
    "\n",
    "Data_Prep = prepare_data.data_preparer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File b'simple-svr-data/raspy-1' does not exist\n",
      "dict_keys(['dusty', 'march', 'direful', 'complete', 'superb', 'poised', 'wait', 'quaint', 'save', 'copy', 'interest', 'separate', 'bright', 'utter', 'bored', 'nondescript', 'license', 'vest', 'dance', 'money', 'languid', 'swim', 'enthusiastic', 'quartz', 'planes', 'spiritual', 'imperfect', 'coal', 'hobbies', 'sound', 'bow', 'squirrel', 'push', 'treatment', 'mine', 'precede', 'weather', 'amazing', 'round', 'stingy', 'signal', 'marry', 'country', 'uncle', 'dust', 'certain', 'loose', 'knock', 'advice', 'confuse', 'animated', 'loving', 'feeling', 'absorbing', 'trick', 'spare', 'rod', 'caption', 'throne', 'clumsy', 'vague', 'tow', 'hang', 'rely', 'tired', 'barbarous', 'pan', 'innocent', 'combative', 'low', 'rub', 'mixed', 'actually', 'faulty', 'thirsty', 'dam', 'doubtful', 'flowers', 'defective', 'frogs', 'outstanding', 'ducks', 'icicle', 'fry', 'load', 'cracker', 'efficient', 'hop', 'fax', 'fancy', 'reading', 'real', 'addicted', 'motion', 'clean', 'unsuitable', 'race', 'aspiring', 'gold', 'check', 'bouncy', 'regret', 'chop', 'various', 'eminent', 'wander', 'living', 'equable', 'cluttered', 'geese', 'tightfisted', 'aftermath', 'quince', 'division', 'board', 'amuck', 'pretty', 'sun', 'person', 'magical', 'invent', 'flap', 'stomach', 'black', 'river', 'town', 'type', 'stereotyped', 'paddle', 'expand', 'puncture', 'cakes', 'measly', 'kitty', 'courageous', 'shoe', 'number', 'third', 'ugliest', 'haircut', 'increase', 'wrathful', 'jog', 'straw', 'whisper', 'kick', 'talented', 'curious'])\n"
     ]
    }
   ],
   "source": [
    "singles = Data_Prep.load_singletons(1)\n",
    "print(singles.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling the Data\n",
    "\n",
    "First, we generate the phoneme and articulatory feature labels from each word. We'll use these to process the data in each file based on the length of the file and how many phonemes it should contain. We scale the FFT windows relative to the length of time we expect an even distribution of phonemes across the file to have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_1 = Data_Prep.load('Sat Mar  4 00:44:23 2017')\n",
    "# data_2 = Data_Prep.load('Sat Mar  4 00:45:02 2017')\n",
    "# data_3 = Data_Prep.load('Sat Mar  4 00:45:47 2017')\n",
    "# data_4 = Data_Prep.load('Sat Mar  4 00:47:01 2017')\n",
    "# data_5 = Data_Prep.load('Sat Mar  4 00:47:36 2017')\n",
    "# data_6 = Data_Prep.load('Sat Mar  4 00:48:09 2017')\n",
    "# data_7 = Data_Prep.load('Sat Mar  4 00:49:05 2017')\n",
    "# data_8 = Data_Prep.load('Sat Mar  4 00:49:41 2017')\n",
    "# data_9 = Data_Prep.load('Sat Mar  4 00:50:22 2017')\n",
    "# data_10 = Data_Prep.load('Sat Mar  4 00:51:17 2017')\n",
    "# data_11 = Data_Prep.load('Sat Mar  4 00:52:02 2017')\n",
    "# data_12 = Data_Prep.load('Sat Mar  4 00:52:38 2017')\n",
    "# data_13 = Data_Prep.load('Sat Mar  4 00:53:24 2017')\n",
    "# data_14 = Data_Prep.load('Sat Mar  4 00:53:51 2017')\n",
    "# data_15 = Data_Prep.load('Sat Mar  4 00:54:25 2017')\n",
    "# data_16 = Data_Prep.load('Sat Mar  4 00:54:57 2017')\n",
    "# data_17 = Data_Prep.load('Sat Mar  4 00:56:01 2017')\n",
    "# data_18 = Data_Prep.load('Sat Mar  4 00:56:35 2017')\n",
    "# data_19 = Data_Prep.load('Sat Mar  4 00:57:21 2017')\n",
    "# data_20 = Data_Prep.load('Sat Mar  4 00:57:49 2017')\n",
    "# data_21 = Data_Prep.load('Sat Mar  4 00:58:59 2017')\n",
    "# data_22 = Data_Prep.load('Sat Mar  4 00:59:53 2017')\n",
    "\n",
    "# data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10, data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20, data_21, data_22]\n",
    "labels = {}\n",
    "windows = {}\n",
    "for word in singles:\n",
    "    label = Output_Prep.transform(word)\n",
    "    num_phonemes = label.shape[0]\n",
    "    labels[word] = label\n",
    "    windows[word] = EMG_Prep.process(singles[word],num_phonemes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0.0       10.0      10.0      20.0      20.0      30.0      30.0   \\\n",
      "0  43.492969  0.020570  2.259229  1.954676  1.681519  1.445389  2.413685   \n",
      "1  47.746875  2.017764  0.095421  0.633403  0.322932  2.490014  1.047570   \n",
      "2  43.325391  1.125540  0.838279  0.147355  0.309692  0.321898  0.573655   \n",
      "3  42.680859  1.142250  0.402145  1.505252  0.509298  0.329306  0.888195   \n",
      "4  44.421094  0.062747  1.107197  0.216720  0.385406  1.835386  1.378310   \n",
      "5  44.098828  0.190692  0.318395  1.432442  0.888541  0.892307  0.651676   \n",
      "\n",
      "      40.0      40.0      50.0     ...        450.0     460.0     460.0  \\\n",
      "0  0.423931  1.066141  1.716362    ...     0.394087  0.043894  0.195630   \n",
      "1  0.822770  4.314441  0.909039    ...     0.924509  0.736296  1.002601   \n",
      "2  4.172037  2.061649  0.181364    ...     1.295144  0.545687  1.338983   \n",
      "3  1.115764  2.908927  1.167312    ...     0.145217  0.530457  0.348105   \n",
      "4  1.094253  2.286328  0.503626    ...     0.123156  2.375713  1.121218   \n",
      "5  2.017346  2.068078  1.491961    ...     0.848477  0.621354  0.129876   \n",
      "\n",
      "      470.0     470.0     480.0     480.0     490.0     490.0     500.0  \n",
      "0  0.931280  1.201105  0.062744  5.302256  1.388680  0.134779  0.360937  \n",
      "1  2.697063  2.946507  2.575922  2.419827  0.139777  0.013146  0.257812  \n",
      "2  1.233442  1.651759  3.648218  1.200767  0.367353  2.532242  1.972266  \n",
      "3  0.031288  0.288097  0.084386  0.425973  1.547000  0.103913  8.005078  \n",
      "4  0.302215  1.993737  0.724461  0.038408  1.562504  4.152462  2.861719  \n",
      "5  1.541042  0.539480  3.644032  1.564031  1.390862  0.138170  1.714453  \n",
      "\n",
      "[6 rows x 100 columns]          manner     place     height vowel\n",
      "L   approximant   lateral  very high    no\n",
      "AY        vowel      back        low   yes\n",
      "S     fricative  alveolar        max    no\n",
      "AH        vowel       mid        mid   yes\n",
      "N         nasal  alveolar        max    no\n",
      "S     fricative  alveolar        max    no        0.0       10.0      10.0      20.0      20.0      30.0      30.0   \\\n",
      "0  40.128516  0.611095  0.466195  0.139994  0.876882  3.630717  0.944673   \n",
      "1  42.822656  0.263133  0.514639  0.498667  0.348171  0.254026  0.673228   \n",
      "2  40.773047  0.232646  1.498370  0.420717  0.700576  0.390744  1.083082   \n",
      "3  40.412109  1.130466  0.028446  0.302547  0.506969  0.086286  0.148870   \n",
      "\n",
      "      40.0      40.0      50.0     ...        450.0     460.0     460.0  \\\n",
      "0  1.934631  1.977457  4.044251    ...     0.846274  1.479742  4.496810   \n",
      "1  0.071211  4.419635  3.565525    ...     0.744419  0.443280  2.277645   \n",
      "2  0.321746  2.798400  0.578301    ...     1.201885  0.466514  1.923584   \n",
      "3  2.214095  2.294595  1.860774    ...     3.055564  1.635510  1.392115   \n",
      "\n",
      "      470.0     470.0     480.0     480.0     490.0     490.0     500.0  \n",
      "0  0.290310  0.027927  0.404562  0.326182  0.523644  0.876017  0.348047  \n",
      "1  1.437687  2.778129  2.041777  0.664612  3.118947  2.551078  2.526563  \n",
      "2  0.498497  3.036519  1.240197  1.766377  3.069163  1.597351  4.369922  \n",
      "3  1.720472  2.801744  1.088663  1.871633  2.846476  0.615603  3.751172  \n",
      "\n",
      "[4 rows x 100 columns]    manner     place     height vowel\n",
      "M   nasal    labial        max    no\n",
      "AH  vowel       mid        mid   yes\n",
      "N   nasal  alveolar        max    no\n",
      "IY  vowel     front  very high   yes\n"
     ]
    }
   ],
   "source": [
    "test_word = 'license'\n",
    "test_word2 = 'money'\n",
    "test_EMG = EMG_Prep.process(singles[test_word], labels[test_word].shape[0])\n",
    "test_EMG2 = EMG_Prep.process(singles[test_word2], labels[test_word2].shape[0])\n",
    "\n",
    "print(test_EMG.head(6), labels[test_word], test_EMG2.head(), labels[test_word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        NaN        inf       inf       inf       inf       inf       inf  \\\n",
      "0  47.914453  1.158442  1.401185  3.283131  0.277644  0.267410  0.169687   \n",
      "1  46.264453  0.050700  0.546690  0.662641  1.239360  0.448413  1.328471   \n",
      "2  50.569922  2.983494  1.049043  0.930923  0.472148  2.044457  0.101294   \n",
      "3  49.770703  0.043322  2.336511  1.358702  0.614687  0.364910  0.341432   \n",
      "4  47.630859  0.727348  0.231554  2.098967  1.644969  1.083569  1.455825   \n",
      "\n",
      "        inf       inf       inf    ...          inf       inf       inf  \\\n",
      "0  1.323168  0.466061  0.956487    ...     1.822187  1.601457  5.380026   \n",
      "1  1.004214  1.435452  3.199529    ...     2.771921  1.710445  3.321455   \n",
      "2  2.701824  2.107786  5.631576    ...     0.459451  2.579507  0.463937   \n",
      "3  0.641346  2.528079  4.349871    ...     0.121954  0.506894  0.841946   \n",
      "4  1.038744  0.158296  4.088807    ...     4.347557  0.907961  1.048890   \n",
      "\n",
      "        inf       inf       inf       inf       inf       inf       inf  \n",
      "0  0.386002  4.816370  1.326837  0.529988  0.105382  0.326328  1.226506  \n",
      "1  3.419234  1.477881  3.613853  0.339698  2.865906  2.082984  1.398406  \n",
      "2  2.079789  0.141080  1.899117  1.523638  4.256511  1.065392  3.166191  \n",
      "3  2.173278  0.094577  0.515186  0.523916  2.125395  3.249366  3.724229  \n",
      "4  2.323690  3.519540  2.780259  1.072922  2.278380  1.437215  0.392524  \n",
      "\n",
      "[5 rows x 129 columns]\n",
      "        NaN        inf       inf       inf       inf       inf       inf  \\\n",
      "0  79.393359  1.208127  1.304589  2.422485  1.164999  3.446019  0.325551   \n",
      "1  79.741406  2.361925  0.994677  1.733643  1.331849  0.841300  1.528747   \n",
      "2  85.065234  1.666814  0.061785  0.264555  0.486377  5.102159  2.264941   \n",
      "3  80.940234  0.394540  1.559391  0.111332  0.301928  1.866864  0.464888   \n",
      "\n",
      "        inf       inf       inf    ...          inf       inf       inf  \\\n",
      "0  1.228754  2.402414  1.621817    ...     1.718118  2.206123  0.279972   \n",
      "1  0.424079  4.442587  2.969721    ...     0.705282  5.119243  1.364245   \n",
      "2  0.279000  0.090286  1.251017    ...     4.664334  1.159358  1.121561   \n",
      "3  0.014468  0.376428  1.893265    ...     3.717185  6.836081  4.577313   \n",
      "\n",
      "        inf       inf       inf       inf       inf       inf       inf  \n",
      "0  2.089128  1.046808  1.096348  1.191874  0.527451  5.073896  2.028844  \n",
      "1  1.505906  1.414606  1.977709  0.892214  0.050346  0.253090  3.233631  \n",
      "2  2.054965  1.074267  2.535528  3.731499  2.924937  2.964596  0.446969  \n",
      "3  0.633559  4.584401  4.797737  0.244429  3.374543  2.378869  0.085734  \n",
      "\n",
      "[4 rows x 217 columns]\n",
      "        NaN        inf       inf       inf       inf       inf       inf  \\\n",
      "0  80.089453  0.616693  3.347435  0.497785  0.804832  0.694482  2.312691   \n",
      "1  81.571875  1.339702  1.305292  1.058622  7.838052  0.100819  0.712712   \n",
      "2  73.953516  0.816664  0.557684  3.373578  1.617704  1.044482  1.526657   \n",
      "3  81.133594  1.186233  0.006163  0.775196  0.577615  2.905291  1.287759   \n",
      "\n",
      "        inf       inf       inf    ...          inf       inf       inf  \\\n",
      "0  0.454764  0.259975  1.070289    ...     1.446301  2.433885  0.730126   \n",
      "1  5.477591  1.559426  1.216253    ...     1.440892  0.209831  0.451137   \n",
      "2  3.403971  0.738120  1.733223    ...     4.519628  4.525811  3.859371   \n",
      "3  1.526209  0.959361  2.124863    ...     6.445461  1.609085  4.473001   \n",
      "\n",
      "        inf       inf       inf       inf       inf       inf       inf  \n",
      "0  4.983581  0.032187  6.156412  4.814700  2.336190  2.116899  1.681955  \n",
      "1  1.392175  2.426805  8.010767  2.630691  6.196147  0.641973  1.610113  \n",
      "2  6.496939  4.197945  1.354443  2.163726  2.098631  2.034597  2.392867  \n",
      "3  1.213608  1.984995  1.858423  1.486340  0.866216  1.336616  1.910383  \n",
      "\n",
      "[4 rows x 217 columns]\n",
      "        NaN        inf       inf       inf       inf       inf       inf  \\\n",
      "0  47.141016  3.405679  2.993956  0.917448  0.695870  0.170638  0.779207   \n",
      "1  45.052734  2.528078  1.165347  0.269065  1.507533  1.375769  2.867192   \n",
      "2  44.704687  2.438750  1.571256  0.301145  0.342361  0.716438  1.101579   \n",
      "3  46.200000  0.294202  0.631844  1.169276  0.021437  2.420020  0.818928   \n",
      "4  43.260937  2.826853  0.780829  2.544873  0.860447  1.117198  1.041461   \n",
      "5  44.047266  0.517635  2.659495  1.168989  0.224406  0.110843  1.897382   \n",
      "6  45.529687  0.181825  1.048647  1.402613  1.513974  1.997488  1.720804   \n",
      "\n",
      "        inf       inf       inf    ...          inf       inf       inf  \\\n",
      "0  1.636100  0.748139  4.059689    ...     0.145372  2.549551  1.970665   \n",
      "1  1.588483  1.243289  1.378044    ...     0.071518  4.782683  1.128920   \n",
      "2  1.681624  1.320823  4.370281    ...     2.581766  1.102099  0.806846   \n",
      "3  2.160734  0.394721  5.031288    ...     0.814779  3.220282  2.065712   \n",
      "4  0.888917  1.274802  2.662670    ...     1.098956  0.122576  3.372853   \n",
      "5  0.385070  0.423945  4.087709    ...     1.015062  0.004074  0.127979   \n",
      "6  1.007772  1.213715  5.268639    ...     3.565471  0.402783  0.313520   \n",
      "\n",
      "        inf       inf       inf       inf       inf       inf       inf  \n",
      "0  0.459773  2.340537  2.208545  0.011987  0.460858  4.019100  3.064154  \n",
      "1  2.721939  1.788922  1.706154  1.817554  2.186594  0.281608  0.048325  \n",
      "2  0.420610  2.103869  0.295807  0.698802  1.117020  1.985047  0.141651  \n",
      "3  3.785742  1.877962  2.560003  1.740654  0.492590  0.229690  0.560789  \n",
      "4  2.257974  0.115146  0.701131  5.001980  0.056177  2.437740  1.963191  \n",
      "5  0.031404  1.255341  2.716062  2.861447  0.118160  8.018671  4.599984  \n",
      "6  1.165478  0.840026  0.225975  0.320139  2.233158  1.463553  0.163965  \n",
      "\n",
      "[7 rows x 125 columns]\n",
      "        NaN        inf       inf       inf       inf       inf       inf  \\\n",
      "0  53.805469  0.542668  2.207801  0.379356  2.835554  1.058113  0.477380   \n",
      "1  51.227344  0.338963  1.283460  0.850669  0.080727  1.997982  1.597389   \n",
      "2  51.059766  0.115036  0.584957  1.052387  0.290964  1.240474  1.214651   \n",
      "3  53.173828  3.532204  1.278936  0.969116  1.129060  1.991554  1.387683   \n",
      "4  52.155469  0.682572  1.153270  2.312973  0.910068  3.860406  4.209212   \n",
      "\n",
      "        inf       inf       inf    ...          inf       inf       inf  \\\n",
      "0  1.242825  1.489692  1.763836    ...     4.774664  6.233113  1.324057   \n",
      "1  3.883502  1.386110  0.429910    ...     1.773298  3.596733  0.521736   \n",
      "2  1.439392  0.699257  3.799803    ...     0.927003  4.627939  3.575941   \n",
      "3  1.865199  0.878358  0.249555    ...     4.392912  1.832328  0.587748   \n",
      "4  1.348712  0.926951  2.956125    ...     0.500444  0.925496  1.084217   \n",
      "\n",
      "        inf       inf       inf       inf       inf       inf       inf  \n",
      "0  0.888490  2.912244  0.982167  0.813537  2.035856  1.340581  0.853969  \n",
      "1  0.067232  4.192373  0.754908  2.057838  0.817542  0.208070  1.229569  \n",
      "2  1.068144  1.351591  1.715971  3.362062  0.325092  1.015303  3.201000  \n",
      "3  1.175952  2.183918  5.203112  1.527783  0.942777  4.248518  2.931977  \n",
      "4  0.600728  0.739774  1.408420  4.050986  4.493737  0.914054  1.314689  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "%autoreload 2\n",
    "\n",
    "# num_files = len(data_list)\n",
    "# labels_frame = pandas.read_csv('austen_subvocal.csv')\n",
    "# trans_labels = Output_Prep.transform(labels_frame.iloc[0][0])\n",
    "# data_1_proc = EMG_Prep.process(data_1)\n",
    "# aligned_data, trans_labels= Output_Prep.zip(data_1_proc, trans_labels, repeat=3)\n",
    "\n",
    "# for file in range(1, num_files):\n",
    "#     trans_labels_iter = Output_Prep.transform(labels_frame.iloc[file][0])\n",
    "#     data_proc_iter = EMG_Prep.process(data_list[file])\n",
    "#     aligned_data_iter, trans_labels_iter = Output_Prep.zip(data_proc_iter, trans_labels_iter, repeat=3)\n",
    "\n",
    "#     aligned_data = aligned_data.append(aligned_data_iter)\n",
    "#     trans_labels = trans_labels.append(trans_labels_iter)\n",
    "    \n",
    "# print('Aligned Data shape:',aligned_data.shape,'Trans labels shape:',trans_labels.shape)\n",
    "for word in labels:\n",
    "#     append labels to the master label dataframe\n",
    "#     Use phonemes to name each series in 'windows' for that word\n",
    "#     Append windows to a master window dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AF Extractor Models\n",
    "\n",
    "These models will be optimized for extracting AF's from the data, before passing those AF's onto an MLPC for identifying the most likely phoneme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number layer sizes: 5 here be layer sizes [(30, 30), (60, 60), (90, 90), (120, 120), (150, 150)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists of parameters for our GridSearch\n",
    "# First, our layer sizes\n",
    "layer_sizes = []\n",
    "for i in range(2,3):\n",
    "    for j in range(0,180,30):\n",
    "        if j:\n",
    "            tup = []\n",
    "            for k in range(i):\n",
    "                tup.append(j)\n",
    "            layer_sizes.append(tuple(tup))\n",
    "print('number layer sizes:',len(layer_sizes),'here be layer sizes',layer_sizes)\n",
    "\n",
    "# Next, our alpha values\n",
    "alphas = [0.0000001,1,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing GridSearch and Assesing Stock MLPC as AF extractor models\n",
    "\n",
    "We setup the objects for performing gridsearch on each one of the Articulatory Feature Extractor models. We also train untuned, stock MLPC models to serve as a performance baseline. We will compare the performance of these baseline, untuned models to our gridsearched models to determine whether gridsearch has in fact improved the model parameters for each AF extractor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.403773584906 place score: 0.283018867925 height score: 0.491823899371 vowel score: 0.592452830189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "# Import other models to try for feature extraction\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "import copy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(aligned_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('pca',PCA(random_state=18)),\n",
    "    ('kbest',SelectKBest(k=1))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('model', MLPC(random_state=12))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'features__pca__n_components':[0.5,0.66,0.9],\n",
    "    'model__solver':['adam'],\n",
    "    'model__hidden_layer_sizes':layer_sizes,\n",
    "    'model__activation':['relu'],\n",
    "    'model__alpha': alphas,\n",
    "    'model__max_iter':[200]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, n_jobs=-1)\n",
    "\n",
    "manner_classifier = MLPC(solver='adam',random_state=3)\n",
    "manner_classifier.fit(X_train, y_train['manner'])\n",
    "m_score = manner_classifier.score(X_test, y_test['manner'])\n",
    "\n",
    "place_classifier = MLPC(solver='adam',random_state=6)\n",
    "place_classifier.fit(X_train, y_train['place'])\n",
    "p_score = place_classifier.score(X_test, y_test['place'])\n",
    "\n",
    "height_classifier = MLPC(solver='adam',random_state=9)\n",
    "height_classifier.fit(X_train, y_train['height'])\n",
    "h_score = height_classifier.score(X_test, y_test['height'])\n",
    "\n",
    "vowel_classifier = MLPC(solver='adam',random_state=12)\n",
    "vowel_classifier.fit(X_train, y_train['vowel'])\n",
    "v_score = vowel_classifier.score(X_test, y_test['vowel'])\n",
    "\n",
    "print('manner score:',m_score,'place score:',p_score,'height score:',h_score,'vowel score:',v_score)\n",
    "# print(data_1_proc.head(50), trans_labels['manner'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.389433962264\n"
     ]
    }
   ],
   "source": [
    "manner_classifier2 = copy.deepcopy(grid_search)\n",
    "manner_classifier2.fit(aligned_data, trans_labels['manner'])\n",
    "m_score2 = manner_classifier2.score(aligned_data, trans_labels['manner'])\n",
    "\n",
    "print('manner score:',m_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place score: 0.280754716981\n"
     ]
    }
   ],
   "source": [
    "place_classifier2 = copy.deepcopy(grid_search)\n",
    "place_classifier2.fit(aligned_data, trans_labels['place'])\n",
    "p_score2 = place_classifier2.score(aligned_data, trans_labels['place'])\n",
    "\n",
    "print('place score:',p_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.504905660377\n"
     ]
    }
   ],
   "source": [
    "height_classifier2 = copy.deepcopy(grid_search)\n",
    "height_classifier2.fit(aligned_data, trans_labels['height'])\n",
    "h_score2 = height_classifier2.score(aligned_data, trans_labels['height'])\n",
    "\n",
    "print('vowel score:',h_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.610566037736\n"
     ]
    }
   ],
   "source": [
    "vowel_classifier2 = copy.deepcopy(grid_search)\n",
    "vowel_classifier2.fit(aligned_data, trans_labels['vowel'])\n",
    "v_score2 = vowel_classifier2.score(aligned_data, trans_labels['vowel'])\n",
    "\n",
    "print('vowel score:',v_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.405031446541\n"
     ]
    }
   ],
   "source": [
    "# Experiment with PCA here\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "manner_union = FeatureUnion([('pca',PCA(n_components=0.03)),('kbest',SelectKBest(k=1))])\n",
    "manner_reduced_data = manner_union.fit_transform(aligned_data, trans_labels['manner'])\n",
    "manner_X_train, manner_X_test, manner_y_train, manner_y_test = train_test_split(manner_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "manner_classifier3 = MLPC(solver='adam',alpha=1000,hidden_layer_sizes=(1),random_state=3,max_iter=300)\n",
    "manner_classifier3.fit(manner_X_train, manner_y_train['manner'])\n",
    "m_score3 = manner_classifier3.score(manner_X_test, manner_y_test['manner'])\n",
    "print('manner score:',m_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place classifier score: 0.161006289308\n"
     ]
    }
   ],
   "source": [
    "place_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "place_reduced_data = place_union.fit_transform(aligned_data, trans_labels['place'])\n",
    "place_X_train, place_X_test, place_y_train, place_y_test = train_test_split(place_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "place_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(120,120),random_state=6,max_iter=300)\n",
    "place_classifier3.fit(place_X_train, place_y_train['place'])\n",
    "p_score3 = place_classifier3.score(place_X_test, place_y_test['place'])\n",
    "print('place classifier score:',p_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height score: 0.353459119497\n"
     ]
    }
   ],
   "source": [
    "height_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "height_reduced_data = height_union.fit_transform(aligned_data, trans_labels['height'])\n",
    "height_X_train, height_X_test, height_y_train, height_y_test = train_test_split(height_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "height_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(180,180),random_state=12,max_iter=300)\n",
    "height_classifier3.fit(height_X_train, height_y_train['height'])\n",
    "h_score3 = height_classifier3.score(height_X_test, height_y_test['height'])\n",
    "print('height score:',h_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.522012578616\n"
     ]
    }
   ],
   "source": [
    "vowel_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "vowel_reduced_data = vowel_union.fit_transform(aligned_data, trans_labels['vowel'])\n",
    "vowel_X_train, vowel_X_test, vowel_y_train, vowel_y_test = train_test_split(vowel_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "vowel_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(180,180),random_state=12,max_iter=300)\n",
    "vowel_classifier3.fit(vowel_X_train, vowel_y_train['vowel'])\n",
    "v_score3 = vowel_classifier3.score(vowel_X_test, vowel_y_test['vowel'])\n",
    "print('vowel score:',v_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0922641509434\n"
     ]
    }
   ],
   "source": [
    "pho_score = phoneme_classifier.score(aligned_data, phoneme_labels)\n",
    "print(pho_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'voiced-fricative': 0, 'vowel': 1, 'fricative': 2, 'nasal': 3, 'approximant': 4, 'voiced-stop': 5, 'aspirated': 6, 'stop': 7, 'dental': 0, 'mid': 1, 'labial': 2, 'mid-front': 3, 'lateral': 4, 'front': 5, 'alveolar': 6, 'back': 7, 'mid-back': 8, 'uknown': 9, 'dorsal': 10, 'retroflex': 11, 'max': 0, 'low': 2, 'very high': 3, 'very-high': 4, 'high': 5, 'mid-low': 6, 'mid-high': 7, 'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer as MLB\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from collections import Counter\n",
    "\n",
    "m_count = Counter()\n",
    "p_count = Counter()\n",
    "h_count = Counter()\n",
    "v_count = Counter()\n",
    "\n",
    "for row in range(trans_labels.shape[0]):\n",
    "    m_count.update([trans_labels.iloc[row]['manner']])\n",
    "    p_count.update([trans_labels.iloc[row]['place']])\n",
    "    h_count.update([trans_labels.iloc[row]['height']])\n",
    "    v_count.update([trans_labels.iloc[row]['vowel']])\n",
    "    \n",
    "counters = [m_count,p_count,h_count,v_count]\n",
    "\n",
    "feature_dict = {}\n",
    "for count in counters:\n",
    "    current = 0\n",
    "    for feature in count.keys():\n",
    "        feature_dict[feature] = current\n",
    "        current += 1\n",
    "        \n",
    "print(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_labels = copy.copy(trans_labels)\n",
    "for row in range(trans_labels.shape[0]):\n",
    "    m_feat = trans_labels.iloc[row]['manner']\n",
    "    p_feat = trans_labels.iloc[row]['place']\n",
    "    h_feat = trans_labels.iloc[row]['height']\n",
    "    v_feat = trans_labels.iloc[row]['vowel']\n",
    "    num_labels.iloc[row]['manner'] = feature_dict[m_feat]\n",
    "    num_labels.iloc[row]['place'] = feature_dict[p_feat]\n",
    "    num_labels.iloc[row]['height'] = feature_dict[h_feat]\n",
    "    num_labels.iloc[row]['vowel'] = feature_dict[v_feat]\n",
    "num_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  1.  0. ...,  1.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
      "    0    1    2    3    4    5    6    7    8    9  ...    20   21   22   23  \\\n",
      "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  0.0  0.0   \n",
      "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  1.0  0.0   \n",
      "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "\n",
      "    24   25   26   27   28   29  \n",
      "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "encoder = OHE()\n",
    "new_labels = encoder.fit_transform(num_labels)\n",
    "print(new_labels.toarray())\n",
    "enc_labels = pandas.DataFrame(new_labels.toarray())\n",
    "print(enc_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(90, 90), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=6, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(aligned_data.axes[1]) + list(enc_labels.axes[1])\n",
    "# print(cols)\n",
    "\n",
    "phoneme_inputs = pandas.DataFrame(columns=cols)\n",
    "phoneme_labels = trans_labels.axes[0]\n",
    "\n",
    "for row in range(aligned_data.shape[0]):\n",
    "    new_row = aligned_data.iloc[row].append(enc_labels.iloc[row])\n",
    "    new_row = new_row.rename(trans_labels.iloc[row].name)\n",
    "    phoneme_inputs = phoneme_inputs.append(new_row)\n",
    "\n",
    "pho_X_train, pho_X_test, pho_y_train, pho_y_test = train_test_split(phoneme_inputs,phoneme_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "phoneme_classifier = MLPC(solver='adam',hidden_layer_sizes=(90,90),random_state=6, max_iter=300)\n",
    "phoneme_classifier.fit(pho_X_train, pho_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923270440252\n"
     ]
    }
   ],
   "source": [
    "pho_score = phoneme_classifier.score(pho_X_test, pho_y_test)\n",
    "print(pho_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoneme model test score: 0.0603773584906\n"
     ]
    }
   ],
   "source": [
    "# feature_extractors = FeatureUnion([\n",
    "#     ('manner_extractor',manner_classifier2.best_estimator_),\n",
    "#     ('place_extractor',place_classifier2.best_estimator_),\n",
    "#     ('height_extractor',height_classifier2.best_estimator_),\n",
    "#     ('vowel_extractor',vowel_classifier2.best_estimator_),\n",
    "#     ('pho_pca',PCA())\n",
    "# ])\n",
    "\n",
    "# pho_pipe = Pipeline([\n",
    "#     ('AF_extractors',feature_extractors),\n",
    "#     ('pho_classifier',MLPC())\n",
    "# ])\n",
    "manner_inputs = manner_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "place_inputs = place_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "height_inputs = height_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "vowel_inputs = vowel_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "raw_inputs = copy.copy(trans_labels)\n",
    "for row in range(len(manner_inputs)):\n",
    "\n",
    "    raw_inputs.iloc[row]['manner'] = manner_inputs[row]\n",
    "    raw_inputs.iloc[row]['place'] = place_inputs[row]\n",
    "    raw_inputs.iloc[row]['height'] = height_inputs[row]\n",
    "    raw_inputs.iloc[row]['vowel'] = vowel_inputs[row]\n",
    "    \n",
    "# print(raw_inputs.head(300))\n",
    "\n",
    "test_num_labels = copy.copy(raw_inputs)\n",
    "for row in range(pho_X_test.shape[0]):\n",
    "    m_feat = raw_inputs.iloc[row]['manner']\n",
    "#     print(m_feat)\n",
    "    p_feat = raw_inputs.iloc[row]['place']\n",
    "    h_feat = raw_inputs.iloc[row]['height']\n",
    "    v_feat = raw_inputs.iloc[row]['vowel']\n",
    "    test_num_labels.iloc[row]['manner'] = feature_dict[m_feat]\n",
    "    test_num_labels.iloc[row]['place'] = feature_dict[p_feat]\n",
    "    test_num_labels.iloc[row]['height'] = feature_dict[h_feat]\n",
    "    test_num_labels.iloc[row]['vowel'] = feature_dict[v_feat]\n",
    "# num_labels.head()\n",
    "\n",
    "encoder = OHE()\n",
    "test_new_labels = encoder.fit_transform(test_num_labels)\n",
    "# print(new_labels.toarray())\n",
    "test_enc_labels = pandas.DataFrame(test_new_labels.toarray())\n",
    "# print(enc_labels.head())\n",
    "\n",
    "cols = list(aligned_data.axes[1]) + list(test_enc_labels.axes[1])\n",
    "# print(cols)\n",
    "\n",
    "test_pho_inputs = pandas.DataFrame(columns=cols)\n",
    "phoneme_labels = trans_labels.axes[0]\n",
    "\n",
    "for row in range(pho_X_test.shape[0]):\n",
    "    new_row = aligned_data.iloc[row].append(test_enc_labels.iloc[row])\n",
    "    new_row = new_row.rename(trans_labels.iloc[row].name)\n",
    "    test_pho_inputs = test_pho_inputs.append(new_row)\n",
    "\n",
    "# pho_pipe.fit(pho_X_train, pho_y_train)\n",
    "pho_test_score = phoneme_classifier.score(test_pho_inputs, pho_y_test)\n",
    "print('phoneme model test score:',pho_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
