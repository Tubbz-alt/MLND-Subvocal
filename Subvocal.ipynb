{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Classes\n",
    "\n",
    "First we get all of our helper modules. The prepare_EMG module will prepare the EMG data for phoneme recognition. The prepare_outputs module will prepare our target labels and align them with our EMG data. The module 'prepare_data' will help us read data from CSV into a dataframe. Finally, 'vis' will help visualize EMG data in both time and frequency domains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.896547109208\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import prepare_EMG, prepare_outputs, prepare_data, vis\n",
    "# autodetector = Output_Prep.detector\n",
    "EMG_Prep = prepare_EMG.EMG_preparer(window_size=60.0)\n",
    "# Output_Prep = prepare_outputs.output_preparer(subvocal_detector = autodetector, window_size=30.0)\n",
    "Output_Prep = prepare_outputs.output_preparer(window_size=60.0,do_grid_search=False)\n",
    "\n",
    "Data_Prep = prepare_data.data_preparer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling the Data\n",
    "\n",
    "First, we need to visualize a few EMG voltage graphs to find some sections that most likely contain no subvocalization. Then, we'll need to find some regions that almost certainly do. These two classes of EMG readouts will serve to train an identifier to help us automatically label EMG windows with phonemes. The model used here will most likely be an SVC, inside \"prepare_outputs\". It will process each EMG window in order, and when it finds one that most likely contains subvocalization, it applies the next phoneme as that window's label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_1 = Data_Prep.load('Sat Mar  4 00:44:23 2017')\n",
    "data_2 = Data_Prep.load('Sat Mar  4 00:45:02 2017')\n",
    "data_3 = Data_Prep.load('Sat Mar  4 00:45:47 2017')\n",
    "data_4 = Data_Prep.load('Sat Mar  4 00:47:01 2017')\n",
    "data_5 = Data_Prep.load('Sat Mar  4 00:47:36 2017')\n",
    "data_6 = Data_Prep.load('Sat Mar  4 00:48:09 2017')\n",
    "data_7 = Data_Prep.load('Sat Mar  4 00:49:05 2017')\n",
    "data_8 = Data_Prep.load('Sat Mar  4 00:49:41 2017')\n",
    "data_9 = Data_Prep.load('Sat Mar  4 00:50:22 2017')\n",
    "data_10 = Data_Prep.load('Sat Mar  4 00:51:17 2017')\n",
    "data_11 = Data_Prep.load('Sat Mar  4 00:52:02 2017')\n",
    "data_12 = Data_Prep.load('Sat Mar  4 00:52:38 2017')\n",
    "data_13 = Data_Prep.load('Sat Mar  4 00:53:24 2017')\n",
    "data_14 = Data_Prep.load('Sat Mar  4 00:53:51 2017')\n",
    "data_15 = Data_Prep.load('Sat Mar  4 00:54:25 2017')\n",
    "data_16 = Data_Prep.load('Sat Mar  4 00:54:57 2017')\n",
    "data_17 = Data_Prep.load('Sat Mar  4 00:56:01 2017')\n",
    "data_18 = Data_Prep.load('Sat Mar  4 00:56:35 2017')\n",
    "data_19 = Data_Prep.load('Sat Mar  4 00:57:21 2017')\n",
    "data_20 = Data_Prep.load('Sat Mar  4 00:57:49 2017')\n",
    "data_21 = Data_Prep.load('Sat Mar  4 00:58:59 2017')\n",
    "data_22 = Data_Prep.load('Sat Mar  4 00:59:53 2017')\n",
    "\n",
    "data_list = [data_1, data_2, data_3, data_4, data_5, data_6, data_7, data_8, data_9, data_10, data_11, data_12, data_13, data_14, data_15, data_16, data_17, data_18, data_19, data_20, data_21, data_22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned Data shape: (5300, 60) Trans labels shape: (5300, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "%autoreload 2\n",
    "\n",
    "num_files = len(data_list)\n",
    "labels_frame = pandas.read_csv('austen_subvocal.csv')\n",
    "trans_labels = Output_Prep.transform(labels_frame.iloc[0][0])\n",
    "data_1_proc = EMG_Prep.process(data_1)\n",
    "aligned_data, trans_labels= Output_Prep.zip(data_1_proc, trans_labels, repeat=3)\n",
    "\n",
    "for file in range(1, num_files):\n",
    "    trans_labels_iter = Output_Prep.transform(labels_frame.iloc[file][0])\n",
    "    data_proc_iter = EMG_Prep.process(data_list[file])\n",
    "    aligned_data_iter, trans_labels_iter = Output_Prep.zip(data_proc_iter, trans_labels_iter, repeat=3)\n",
    "\n",
    "    aligned_data = aligned_data.append(aligned_data_iter)\n",
    "    trans_labels = trans_labels.append(trans_labels_iter)\n",
    "    \n",
    "print('Aligned Data shape:',aligned_data.shape,'Trans labels shape:',trans_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AF Extractor Models\n",
    "\n",
    "These models will be optimized for extracting AF's from the data, before passing those AF's onto an MLPC for identifying the most likely phoneme. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number layer sizes: 5 here be layer sizes [(30, 30), (60, 60), (90, 90), (120, 120), (150, 150)]\n"
     ]
    }
   ],
   "source": [
    "# Prepare lists of parameters for our GridSearch\n",
    "# First, our layer sizes\n",
    "layer_sizes = []\n",
    "for i in range(2,3):\n",
    "    for j in range(0,180,30):\n",
    "        if j:\n",
    "            tup = []\n",
    "            for k in range(i):\n",
    "                tup.append(j)\n",
    "            layer_sizes.append(tuple(tup))\n",
    "print('number layer sizes:',len(layer_sizes),'here be layer sizes',layer_sizes)\n",
    "\n",
    "# Next, our alpha values\n",
    "alphas = [0.0000001,1,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing GridSearch and Assesing Stock MLPC as AF extractor models\n",
    "\n",
    "We setup the objects for performing gridsearch on each one of the Articulatory Feature Extractor models. We also train untuned, stock MLPC models to serve as a performance baseline. We will compare the performance of these baseline, untuned models to our gridsearched models to determine whether gridsearch has in fact improved the model parameters for each AF extractor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.403773584906 place score: 0.283018867925 height score: 0.491823899371 vowel score: 0.592452830189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLPC\n",
    "# Import other models to try for feature extraction\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "import copy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(aligned_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('pca',PCA(random_state=18)),\n",
    "    ('kbest',SelectKBest(k=1))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', combined_features),\n",
    "    ('model', MLPC(random_state=12))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'features__pca__n_components':[0.5,0.66,0.9],\n",
    "    'model__solver':['adam'],\n",
    "    'model__hidden_layer_sizes':layer_sizes,\n",
    "    'model__activation':['relu'],\n",
    "    'model__alpha': alphas,\n",
    "    'model__max_iter':[200]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, n_jobs=-1)\n",
    "\n",
    "manner_classifier = MLPC(solver='adam',random_state=3)\n",
    "manner_classifier.fit(X_train, y_train['manner'])\n",
    "m_score = manner_classifier.score(X_test, y_test['manner'])\n",
    "\n",
    "place_classifier = MLPC(solver='adam',random_state=6)\n",
    "place_classifier.fit(X_train, y_train['place'])\n",
    "p_score = place_classifier.score(X_test, y_test['place'])\n",
    "\n",
    "height_classifier = MLPC(solver='adam',random_state=9)\n",
    "height_classifier.fit(X_train, y_train['height'])\n",
    "h_score = height_classifier.score(X_test, y_test['height'])\n",
    "\n",
    "vowel_classifier = MLPC(solver='adam',random_state=12)\n",
    "vowel_classifier.fit(X_train, y_train['vowel'])\n",
    "v_score = vowel_classifier.score(X_test, y_test['vowel'])\n",
    "\n",
    "print('manner score:',m_score,'place score:',p_score,'height score:',h_score,'vowel score:',v_score)\n",
    "# print(data_1_proc.head(50), trans_labels['manner'].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.389433962264\n"
     ]
    }
   ],
   "source": [
    "manner_classifier2 = copy.deepcopy(grid_search)\n",
    "manner_classifier2.fit(aligned_data, trans_labels['manner'])\n",
    "m_score2 = manner_classifier2.score(aligned_data, trans_labels['manner'])\n",
    "\n",
    "print('manner score:',m_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place score: 0.280754716981\n"
     ]
    }
   ],
   "source": [
    "place_classifier2 = copy.deepcopy(grid_search)\n",
    "place_classifier2.fit(aligned_data, trans_labels['place'])\n",
    "p_score2 = place_classifier2.score(aligned_data, trans_labels['place'])\n",
    "\n",
    "print('place score:',p_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.504905660377\n"
     ]
    }
   ],
   "source": [
    "height_classifier2 = copy.deepcopy(grid_search)\n",
    "height_classifier2.fit(aligned_data, trans_labels['height'])\n",
    "h_score2 = height_classifier2.score(aligned_data, trans_labels['height'])\n",
    "\n",
    "print('vowel score:',h_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/brian/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.610566037736\n"
     ]
    }
   ],
   "source": [
    "vowel_classifier2 = copy.deepcopy(grid_search)\n",
    "vowel_classifier2.fit(aligned_data, trans_labels['vowel'])\n",
    "v_score2 = vowel_classifier2.score(aligned_data, trans_labels['vowel'])\n",
    "\n",
    "print('vowel score:',v_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manner score: 0.405031446541\n"
     ]
    }
   ],
   "source": [
    "# Experiment with PCA here\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "manner_union = FeatureUnion([('pca',PCA(n_components=0.03)),('kbest',SelectKBest(k=1))])\n",
    "manner_reduced_data = manner_union.fit_transform(aligned_data, trans_labels['manner'])\n",
    "manner_X_train, manner_X_test, manner_y_train, manner_y_test = train_test_split(manner_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "manner_classifier3 = MLPC(solver='adam',alpha=1000,hidden_layer_sizes=(1),random_state=3,max_iter=300)\n",
    "manner_classifier3.fit(manner_X_train, manner_y_train['manner'])\n",
    "m_score3 = manner_classifier3.score(manner_X_test, manner_y_test['manner'])\n",
    "print('manner score:',m_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place classifier score: 0.161006289308\n"
     ]
    }
   ],
   "source": [
    "place_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "place_reduced_data = place_union.fit_transform(aligned_data, trans_labels['place'])\n",
    "place_X_train, place_X_test, place_y_train, place_y_test = train_test_split(place_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "place_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(120,120),random_state=6,max_iter=300)\n",
    "place_classifier3.fit(place_X_train, place_y_train['place'])\n",
    "p_score3 = place_classifier3.score(place_X_test, place_y_test['place'])\n",
    "print('place classifier score:',p_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height score: 0.353459119497\n"
     ]
    }
   ],
   "source": [
    "height_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "height_reduced_data = height_union.fit_transform(aligned_data, trans_labels['height'])\n",
    "height_X_train, height_X_test, height_y_train, height_y_test = train_test_split(height_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "height_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(180,180),random_state=12,max_iter=300)\n",
    "height_classifier3.fit(height_X_train, height_y_train['height'])\n",
    "h_score3 = height_classifier3.score(height_X_test, height_y_test['height'])\n",
    "print('height score:',h_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel score: 0.522012578616\n"
     ]
    }
   ],
   "source": [
    "vowel_union = FeatureUnion([('pca',PCA(n_components=0.9)),('kbest',SelectKBest(k=1))])\n",
    "vowel_reduced_data = vowel_union.fit_transform(aligned_data, trans_labels['vowel'])\n",
    "vowel_X_train, vowel_X_test, vowel_y_train, vowel_y_test = train_test_split(vowel_reduced_data, trans_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "\n",
    "vowel_classifier3 = MLPC(solver='adam',alpha=0.00001,hidden_layer_sizes=(180,180),random_state=12,max_iter=300)\n",
    "vowel_classifier3.fit(vowel_X_train, vowel_y_train['vowel'])\n",
    "v_score3 = vowel_classifier3.score(vowel_X_test, vowel_y_test['vowel'])\n",
    "print('vowel score:',v_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0922641509434\n"
     ]
    }
   ],
   "source": [
    "pho_score = phoneme_classifier.score(aligned_data, phoneme_labels)\n",
    "print(pho_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'voiced-fricative': 0, 'vowel': 1, 'fricative': 2, 'nasal': 3, 'approximant': 4, 'voiced-stop': 5, 'aspirated': 6, 'stop': 7, 'dental': 0, 'mid': 1, 'labial': 2, 'mid-front': 3, 'lateral': 4, 'front': 5, 'alveolar': 6, 'back': 7, 'mid-back': 8, 'uknown': 9, 'dorsal': 10, 'retroflex': 11, 'max': 0, 'low': 2, 'very high': 3, 'very-high': 4, 'high': 5, 'mid-low': 6, 'mid-high': 7, 'no': 0, 'yes': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.preprocessing import MultiLabelBinarizer as MLB\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from collections import Counter\n",
    "\n",
    "m_count = Counter()\n",
    "p_count = Counter()\n",
    "h_count = Counter()\n",
    "v_count = Counter()\n",
    "\n",
    "for row in range(trans_labels.shape[0]):\n",
    "    m_count.update([trans_labels.iloc[row]['manner']])\n",
    "    p_count.update([trans_labels.iloc[row]['place']])\n",
    "    h_count.update([trans_labels.iloc[row]['height']])\n",
    "    v_count.update([trans_labels.iloc[row]['vowel']])\n",
    "    \n",
    "counters = [m_count,p_count,h_count,v_count]\n",
    "\n",
    "feature_dict = {}\n",
    "for count in counters:\n",
    "    current = 0\n",
    "    for feature in count.keys():\n",
    "        feature_dict[feature] = current\n",
    "        current += 1\n",
    "        \n",
    "print(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_labels = copy.copy(trans_labels)\n",
    "for row in range(trans_labels.shape[0]):\n",
    "    m_feat = trans_labels.iloc[row]['manner']\n",
    "    p_feat = trans_labels.iloc[row]['place']\n",
    "    h_feat = trans_labels.iloc[row]['height']\n",
    "    v_feat = trans_labels.iloc[row]['vowel']\n",
    "    num_labels.iloc[row]['manner'] = feature_dict[m_feat]\n",
    "    num_labels.iloc[row]['place'] = feature_dict[p_feat]\n",
    "    num_labels.iloc[row]['height'] = feature_dict[h_feat]\n",
    "    num_labels.iloc[row]['vowel'] = feature_dict[v_feat]\n",
    "num_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  1. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  1.  0. ...,  1.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
      "    0    1    2    3    4    5    6    7    8    9  ...    20   21   22   23  \\\n",
      "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 ...   0.0  1.0  0.0  0.0   \n",
      "2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  1.0  0.0   \n",
      "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
      "\n",
      "    24   25   26   27   28   29  \n",
      "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "encoder = OHE()\n",
    "new_labels = encoder.fit_transform(num_labels)\n",
    "print(new_labels.toarray())\n",
    "enc_labels = pandas.DataFrame(new_labels.toarray())\n",
    "print(enc_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(90, 90), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=6, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(aligned_data.axes[1]) + list(enc_labels.axes[1])\n",
    "# print(cols)\n",
    "\n",
    "phoneme_inputs = pandas.DataFrame(columns=cols)\n",
    "phoneme_labels = trans_labels.axes[0]\n",
    "\n",
    "for row in range(aligned_data.shape[0]):\n",
    "    new_row = aligned_data.iloc[row].append(enc_labels.iloc[row])\n",
    "    new_row = new_row.rename(trans_labels.iloc[row].name)\n",
    "    phoneme_inputs = phoneme_inputs.append(new_row)\n",
    "\n",
    "pho_X_train, pho_X_test, pho_y_train, pho_y_test = train_test_split(phoneme_inputs,phoneme_labels, test_size=0.15, random_state=12)\n",
    "\n",
    "phoneme_classifier = MLPC(solver='adam',hidden_layer_sizes=(90,90),random_state=6, max_iter=300)\n",
    "phoneme_classifier.fit(pho_X_train, pho_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923270440252\n"
     ]
    }
   ],
   "source": [
    "pho_score = phoneme_classifier.score(pho_X_test, pho_y_test)\n",
    "print(pho_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoneme model test score: 0.0603773584906\n"
     ]
    }
   ],
   "source": [
    "# feature_extractors = FeatureUnion([\n",
    "#     ('manner_extractor',manner_classifier2.best_estimator_),\n",
    "#     ('place_extractor',place_classifier2.best_estimator_),\n",
    "#     ('height_extractor',height_classifier2.best_estimator_),\n",
    "#     ('vowel_extractor',vowel_classifier2.best_estimator_),\n",
    "#     ('pho_pca',PCA())\n",
    "# ])\n",
    "\n",
    "# pho_pipe = Pipeline([\n",
    "#     ('AF_extractors',feature_extractors),\n",
    "#     ('pho_classifier',MLPC())\n",
    "# ])\n",
    "manner_inputs = manner_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "place_inputs = place_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "height_inputs = height_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "vowel_inputs = vowel_classifier.predict(pho_X_test.iloc[:,0:60])\n",
    "raw_inputs = copy.copy(trans_labels)\n",
    "for row in range(len(manner_inputs)):\n",
    "\n",
    "    raw_inputs.iloc[row]['manner'] = manner_inputs[row]\n",
    "    raw_inputs.iloc[row]['place'] = place_inputs[row]\n",
    "    raw_inputs.iloc[row]['height'] = height_inputs[row]\n",
    "    raw_inputs.iloc[row]['vowel'] = vowel_inputs[row]\n",
    "    \n",
    "# print(raw_inputs.head(300))\n",
    "\n",
    "test_num_labels = copy.copy(raw_inputs)\n",
    "for row in range(pho_X_test.shape[0]):\n",
    "    m_feat = raw_inputs.iloc[row]['manner']\n",
    "#     print(m_feat)\n",
    "    p_feat = raw_inputs.iloc[row]['place']\n",
    "    h_feat = raw_inputs.iloc[row]['height']\n",
    "    v_feat = raw_inputs.iloc[row]['vowel']\n",
    "    test_num_labels.iloc[row]['manner'] = feature_dict[m_feat]\n",
    "    test_num_labels.iloc[row]['place'] = feature_dict[p_feat]\n",
    "    test_num_labels.iloc[row]['height'] = feature_dict[h_feat]\n",
    "    test_num_labels.iloc[row]['vowel'] = feature_dict[v_feat]\n",
    "# num_labels.head()\n",
    "\n",
    "encoder = OHE()\n",
    "test_new_labels = encoder.fit_transform(test_num_labels)\n",
    "# print(new_labels.toarray())\n",
    "test_enc_labels = pandas.DataFrame(test_new_labels.toarray())\n",
    "# print(enc_labels.head())\n",
    "\n",
    "cols = list(aligned_data.axes[1]) + list(test_enc_labels.axes[1])\n",
    "# print(cols)\n",
    "\n",
    "test_pho_inputs = pandas.DataFrame(columns=cols)\n",
    "phoneme_labels = trans_labels.axes[0]\n",
    "\n",
    "for row in range(pho_X_test.shape[0]):\n",
    "    new_row = aligned_data.iloc[row].append(test_enc_labels.iloc[row])\n",
    "    new_row = new_row.rename(trans_labels.iloc[row].name)\n",
    "    test_pho_inputs = test_pho_inputs.append(new_row)\n",
    "\n",
    "# pho_pipe.fit(pho_X_train, pho_y_train)\n",
    "pho_test_score = phoneme_classifier.score(test_pho_inputs, pho_y_test)\n",
    "print('phoneme model test score:',pho_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
